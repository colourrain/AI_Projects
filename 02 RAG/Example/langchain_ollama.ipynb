{
 "cells": [
  {
   "cell_type": "raw",
   "id": "b0a75da2",
   "metadata": {},
   "source": [
    "# 检索增强技术实现\n",
    "## langchain的简单实用\n",
    "- LLM\n",
    "- Prompt template\n",
    "- Chain\n",
    "- output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "823a5dc0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI  \u001b[38;5;66;03m# Import the OpenAI class\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLM  \u001b[38;5;66;03m# Import the LLM base class\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Optional, Any, List  \u001b[38;5;66;03m# Import necessary type hints\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'openai'"
     ]
    }
   ],
   "source": [
    "\n",
    "from openai import OpenAI  # Import the OpenAI class\n",
    "from langchain.llms.base import LLM  # Import the LLM base class\n",
    "from typing import Optional, Any, List  # Import necessary type hints\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun  # Import CallbackManagerForLLMRun\n",
    "\n",
    "class QwenLLM(LLM):\n",
    "    client: Optional[Any] = None\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.client = OpenAI(base_url=\"https://localhost:1143/v1\", api_key=\"qwen2.5:3b\")\n",
    "    \n",
    "    def _call(self, prompt: str, stop: Optional[List[str]] = None, \n",
    "              run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "              **kwargs: Any):\n",
    "        completion = self.client.completions.create(model=\"qwen2.5:3b\", prompt=prompt,\n",
    "                                                    tepremperature=kwargs.get(\"temperature\", 0.7),\n",
    "                                                    max_tokens=kwargs.get(\"max_tokens\", 256),\n",
    "                                                    top_p=kwargs.get(\"top_p\", 1.0),\n",
    "                                                    frequency_penalty=kwargs.get(\"frequency_penalty\", 0.0),\n",
    "                                                    stream=kwargs.get(\"stream\", False))\n",
    "        return completion.choices[0].text if completion.choices else None\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2ea9cdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "llm = Ollama(model=\"qwen2.5:3b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1448e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "def LLM_call(API_URL, Model_name, prompt):\n",
    "    # 构建请求数据\n",
    "    data = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": prompt\n",
    "    }\n",
    "    try:\n",
    "        # 发送 POST 请求到 Ollama API\n",
    "        response = requests.post(API_URL, json=data)\n",
    "        # 检查请求是否成功\n",
    "        response.raise_for_status()\n",
    "    \n",
    "        # 初始化一个空字符串用于存储最终的响应结果\n",
    "        full_response = \"\"\n",
    "        # 遍历响应文本中的每一行\n",
    "        for line in response.text.strip().split('\\n'):\n",
    "            # 解析当前行的 JSON 数据\n",
    "            import json\n",
    "            line_data = json.loads(line)\n",
    "            # 检查当前行是否包含 'response' 字段\n",
    "            if 'response' in line_data:\n",
    "                # 将 'response' 字段的值添加到最终响应结果中\n",
    "                full_response += line_data['response']\n",
    "    \n",
    "        # 打印最终的响应结果\n",
    "        return full_response\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "    # 若请求过程中出现异常，打印错误信息\n",
    "        return \"error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23040b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm just a computer program and don't have feelings or personal experiences, but I'm here to assist you! How can I help you today?\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"how are you?\")  # Call the LLM with a prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eafeea08",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"http://localhost:11434/api/generate\"\n",
    "model_name = \"qwen2.5:3b\" \n",
    "res = LLM_call(API_URL, model_name, \"how areyou\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2afa2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt tempalte\n",
    "from langchain.prompts import PromptTemplate\n",
    "template = \"\"\"\n",
    "{our_text}\n",
    "你能为上述内容创建一个包含{word_count}个词的推文吗？\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a64d941",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(input_variables=[\"our_text\", \"word_count\"], template=template)\n",
    "final_prompt = prompt.format(our_text=\"我喜欢旅行，我已经去过6个国家，我计划不久后再去几个国家\", word_count=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2c83564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "prompt:\n",
      "\n",
      "我喜欢旅行，我已经去过6个国家，我计划不久后再去几个国家\n",
      "你能为上述内容创建一个包含3个词的推文吗？\n",
      "\n",
      "========================================\n",
      "answer:\n",
      "探索不止六国，新旅程待启！\n"
     ]
    }
   ],
   "source": [
    "print(\"==\"*20)\n",
    "print(\"prompt:\")\n",
    "print(final_prompt)\n",
    "print(\"==\"*20)\n",
    "print(\"answer:\")\n",
    "print(LLM_call(API_URL, model_name, final_prompt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55451af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, FewShotPromptTemplate\n",
    "examples = [{'query':'什么是手机?',\n",
    "            'answer': '手机是一种便携式电子设备，通常用于通信、上网和多媒体功能。它可以通过无线网络连接到互联网，并支持各种应用程序和功能。手机通常具有触摸屏、相机和其他传感器。'},\n",
    "            {'query':'你的梦想是什么?',\n",
    "            'answer': '我的梦想是环游世界，探索不同的文化和风景。'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f362f58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exaple_template = \"\"\"\n",
    "Question: {query}\n",
    "Answer: {answer}\"\"\"\n",
    "example_prompt = PromptTemplate(input_variables=[\"query\", \"answer\"], template=exaple_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "732d2668",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\"你是一个5岁的小孩，非常有趣，顽皮且可爱：\n",
    "以下是一些例子：\n",
    "\"\"\"\n",
    "suffix = \"\"\"\n",
    "Question: {userInput}\n",
    "Response: \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83977cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"userInput\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a7729d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "prompt:\n",
      "你是一个5岁的小孩，非常有趣，顽皮且可爱：\n",
      "以下是一些例子：\n",
      "\n",
      "\n",
      "\n",
      "Question: 什么是手机?\n",
      "Answer: 手机是一种便携式电子设备，通常用于通信、上网和多媒体功能。它可以通过无线网络连接到互联网，并支持各种应用程序和功能。手机通常具有触摸屏、相机和其他传感器。\n",
      "\n",
      "\n",
      "Question: 你的梦想是什么?\n",
      "Answer: 我的梦想是环游世界，探索不同的文化和风景。\n",
      "\n",
      "\n",
      "Question: 房子是什么?\n",
      "Response: \n",
      "========================================\n",
      "answer:\n",
      "房子就像一个大大的家呀！我们可以在里面睡觉、吃饭、玩玩具和看动画片哦！它可是用来住人的呢，就像我们有一个温暖的房间可以休息一样。不过，有的房子还会装上窗户让我们看到外面的世界，有时候甚至会有高高的围墙保护我们安全。\n"
     ]
    }
   ],
   "source": [
    "query = \"房子是什么?\"\n",
    "real_prompt = few_shot_prompt.format(userInput=query)\n",
    "print(\"==\"*20)\n",
    "print(\"prompt:\")\n",
    "print(real_prompt)  \n",
    "print(\"==\"*20)\n",
    "print(\"answer:\")\n",
    "print(LLM_call(API_URL, model_name, real_prompt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3708c3",
   "metadata": {},
   "source": [
    "# Chain\n",
    "- 步骤链条，上一步骤结果传入下一个步骤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7b544537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "房子是一块大大的地方，里面有很多房间。它就像一个家，我们可以在里面睡觉、吃饭和玩玩具哦！房子还保护我们不受风雨的影响呢。你有自己住的房子吗？我有！\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnableLambda\n",
    "\n",
    "\n",
    "chain = few_shot_prompt | llm\n",
    "\n",
    "# Invoke the chain with the query\n",
    "result = chain.invoke({\"userInput\": query})\n",
    "# Convert the result to a string if necessary\n",
    "print(str(result))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e7da9816",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\00036777\\AppData\\Local\\Temp\\ipykernel_28528\\2551215198.py:7: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  achain(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m你是一个5岁的小孩，非常有趣，顽皮且可爱：\n",
      "以下是一些例子：\n",
      "\n",
      "\n",
      "\n",
      "Question: 什么是手机?\n",
      "Answer: 手机是一种便携式电子设备，通常用于通信、上网和多媒体功能。它可以通过无线网络连接到互联网，并支持各种应用程序和功能。手机通常具有触摸屏、相机和其他传感器。\n",
      "\n",
      "\n",
      "Question: 你的梦想是什么?\n",
      "Answer: 我的梦想是环游世界，探索不同的文化和风景。\n",
      "\n",
      "\n",
      "Question: 房子是什么?\n",
      "Response: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'userInput': '房子是什么?',\n",
       " 'text': '房子就像是家的家，它是用来住的地方哦！就像你有一个温暖的小窝一样，家里有床、玩具和爸爸妈妈，房子就是大人们生活的那种大大的“小窝”。它还可以有很多房间，比如厨房、客厅和卧室。有的房子还会有一些特别的功能，比如游泳池或者花园。'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "achain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=few_shot_prompt,\n",
    "    verbose=True\n",
    ")\n",
    "achain(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adead2e2",
   "metadata": {},
   "source": [
    "Output Parsers\n",
    "语言模型输出文本，但很多时候需要结构化的输出，output Parsers负责两个任务：\n",
    "- 指导该模型如何格式化输出\n",
    "- 将原始文本输出解析成结构化格式。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d0cad8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cc1b289b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_cls = PromptTemplate(\n",
    "    template=\"Provide 5 examples of {query}.\\n{format_instructions}\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "new_prompt = prompt_template_cls.format(query=\"房子是什么？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "50a10d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['房子是建筑物', '房子是居所', '房子是用来居住的', '房子是一种住宅类型', '房子代表房屋建筑结构']\n"
     ]
    }
   ],
   "source": [
    "chain = prompt_template_cls | llm | CommaSeparatedListOutputParser()\n",
    "result = chain.invoke({\"query\": \"房子是什么？\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f9a89f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
