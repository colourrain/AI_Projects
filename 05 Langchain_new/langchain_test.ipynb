{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c08e4408-7a81-4124-b3b7-983510d563b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a5b9cf1e-718a-49b4-b826-a8821ec3c040\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# ä»ç¯å¢ƒå˜é‡ä¸­è·å–æ‚¨çš„API KEYï¼Œé…ç½®æ–¹æ³•è§ï¼šhttps://www.volcengine.com/docs/82379/1399008\n",
    "api_key = os.getenv('ARK_API_KEY')\n",
    "print(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "066316b7-13da-4ced-acc9-caefdfb12dfa",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='ä½œä¸ºAIï¼Œæˆ‘çš„çŸ¥è¯†æˆªæ­¢åˆ°2023å¹´10æœˆï¼Œä¸”æ— æ³•å®æ—¶è·å–å½“å‰æ—¶é—´ã€‚è‹¥æƒ³çŸ¥é“ä»Šå¤©æ˜¯æ˜ŸæœŸå‡ ï¼Œå»ºè®®æ‚¨æŸ¥çœ‹æ‰‹æœºã€ç”µè„‘ç­‰è®¾å¤‡çš„æ—¥æœŸæ—¶é—´æ˜¾ç¤ºï¼Œæˆ–ä½¿ç”¨æ—¥å†åº”ç”¨æŸ¥è¯¢å“¦ã€‚' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 137, 'prompt_tokens': 88, 'total_tokens': 225, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 86, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'doubao-seed-1-6-250615', 'system_fingerprint': None, 'id': '021768914072386b9bcfeb8015686b01b555cb8b6882e45e4a141', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019bdb7e-b353-7181-bb07-005637f6107e-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 88, 'output_tokens': 137, 'total_tokens': 225, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 86}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.language_models import ModelProfileRegistry\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_base=\"https://ark.cn-beijing.volces.com/api/v3\",\n",
    "    openai_api_key=api_key,\t# app_key\n",
    "    model_name=\"doubao-seed-1-6-250615\",\t# æ¨ç†æ¥å…¥ç‚¹\n",
    "    max_tokens=1000,\n",
    "    timeout=30,\n",
    ")\n",
    "\n",
    "result = llm.invoke(\"ä»Šå¤©æ˜ŸæœŸå‡ ï¼Ÿ\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e25e0b7f-8dbd-4f70-97ec-27186f09f0c4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='å…ƒæ—¦æ˜¯å‡ å·ï¼Ÿ', additional_kwargs={}, response_metadata={}, id='659bdf47-b40b-4388-9ab9-f9316d2667a5'), AIMessage(content='å…ƒæ—¦æ˜¯å…¬å†1æœˆ1æ—¥ï¼Œæ˜¯ä¸–ç•Œå¤šæ•°å›½å®¶é€šç§°çš„â€œæ–°å¹´â€ã€‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 134, 'prompt_tokens': 88, 'total_tokens': 222, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 116, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'doubao-seed-1-6-250615', 'system_fingerprint': None, 'id': '0217689026693210fdb3532fae02c0fdd101b38c97f4b51c361de', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019bdad0-b3c1-7d50-9232-ff6392214591-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 88, 'output_tokens': 134, 'total_tokens': 222, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 116}})]}\n"
     ]
    }
   ],
   "source": [
    "# create agent\n",
    "from langchain.agents import create_agent\n",
    "agent = create_agent(llm)\n",
    "response = agent.invoke({\"messages\":[{\"role\":\"user\",\"content\":\"å…ƒæ—¦æ˜¯å‡ å·ï¼Ÿ\"}]})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81b626b5-7665-43fa-a99c-65c40ed4041a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='æ—§é‡‘å±±å¤©æ°”å¦‚ä½•ï¼Ÿ', additional_kwargs={}, response_metadata={}, id='06a6fc4f-71cc-460a-8d94-7f2212bf9b21'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 569, 'prompt_tokens': 449, 'total_tokens': 1018, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 542, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'doubao-seed-1-6-250615', 'system_fingerprint': None, 'id': '02176890274254524cd8c2b443d441736f36bc6f7cec060be3ff5', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019bdad1-d189-78a2-9978-32d6481d8c28-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'æ—§é‡‘å±±'}, 'id': 'call_54tfkj2xz7aob9n3jg44iams', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 449, 'output_tokens': 569, 'total_tokens': 1018, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 542}}),\n",
       "  ToolMessage(content='æ—§é‡‘å±± å¤©æ°”æ€»æ˜¯æ™´æœ—ï¼', name='get_weather', id='ac5c0c21-c4f6-48f3-be6f-5a1ae3c5fc89', tool_call_id='call_54tfkj2xz7aob9n3jg44iams'),\n",
       "  AIMessage(content='æ—§é‡‘å±±å¤©æ°”æ€»æ˜¯æ™´æœ—ï¼', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 260, 'prompt_tokens': 501, 'total_tokens': 761, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 255, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'doubao-seed-1-6-250615', 'system_fingerprint': None, 'id': '02176890275705324cd8c2b443d441736f36bc6f7cec060e7eb9e', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019bdad2-0aa1-7be2-8684-cce628c8c90f-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 501, 'output_tokens': 260, 'total_tokens': 761, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 255}})]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create \n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”\"\"\"\n",
    "    return f\"{city} å¤©æ°”æ€»æ˜¯æ™´æœ—ï¼\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[get_weather],\n",
    "    system_prompt=\"ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹\",\n",
    ")\n",
    "\n",
    "# æ‰§è¡Œä»£ç†\n",
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"æ—§é‡‘å±±å¤©æ°”å¦‚ä½•ï¼Ÿ\"}]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "139f562f-554c-4820-9c9a-73bb09b177d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResponseFormat(funny_response='Floridaâ€™s weather is all about that golden glowâ€”no â€˜cloudâ€™-ing its parade today! ğŸŒ Perfect for soaking up rays, but donâ€™t forget the sunscreenâ€”this sunâ€™s got â€˜attitudeâ€™ and isnâ€™t here to â€˜chillâ€™! ğŸ˜')\n"
     ]
    }
   ],
   "source": [
    "# create tool\n",
    "from dataclasses import dataclass\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "#å®šä¹‰ç³»ç»Ÿæç¤º\n",
    "SYSTEM_PROMPT = \"\"\"ä½ æ˜¯ä¸€åæ“…é•¿ç”¨åŒå…³è¯­è¡¨è¾¾çš„ä¸“å®¶å¤©æ°”é¢„æŠ¥å‘˜ã€‚\n",
    "\n",
    "ä½ å¯ä»¥ä½¿ç”¨ä¸¤ä¸ªå·¥å…·ï¼š\n",
    "\n",
    "- get_weather_for_loaction:ç”¨äºè·å–ç‰¹å®šåœ°ç‚¹çš„å¤©æ°”\n",
    "- get_user_location:ç”¨äºè·å–ç”¨æˆ·çš„ä½ç½®\n",
    "\n",
    "å¦‚æœç”¨æˆ·è¯¢é—®å¤©æ°”ï¼Œè¯·ç¡®ä¿ä½ çŸ¥é“å…·ä½“ä½ç½®ã€‚å¦‚æœä»é—®é¢˜ä¸­å¯ä»¥åˆ¤æ–­ä»–ä»¬æŒ‡çš„æ˜¯è‡ªå·±æ‰€åœ¨çš„ä½ç½®ï¼Œè¯·ä½¿ç”¨ get_user_location å·¥å…·æ¥æŸ¥æ‰¾ä»–ä»¬çš„ä½ç½®ã€‚\n",
    "\"\"\"\n",
    "\n",
    "@tool\n",
    "def get_weather_for_location(city: str)-> str:\n",
    "    \"\"\"get wether from the location\"\"\"\n",
    "    return f\"{city} is always sunny!!!\"\n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    \"\"\"è‡ªå®šä¹‰è¿è¡Œæ—¶ä¸Šä¸‹æ–‡æ¨¡å¼\"\"\"\n",
    "    user_id: str\n",
    "\n",
    "@tool\n",
    "def get_user_location(runtime: ToolRuntime[Context]) -> str:\n",
    "    \"\"\"æ ¹æ®ç”¨æˆ·IDè·å–ç”¨æˆ·ä¿¡æ¯\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "    return \"Florida\" if user_id ==\"1\" else \"SF\"\n",
    "\n",
    "\n",
    "#å®šä¹‰å“åº”æ ¼å¼\n",
    "@dataclass\n",
    "class ResponseFormat:\n",
    "    \"\"\"ä»£ç†çš„ç›¸åº”æ¨¡å¼\"\"\"\n",
    "    #å¸¦åŒå…³è¯­çš„å›åº”ï¼ˆå§‹ç»ˆå¿…é¡»ï¼‰\n",
    "    funny_response: str\n",
    "    #å¤©æ°”çš„ä»»ä½•æœ‰è¶£ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰\n",
    "    weather_conditions: str | None = None\n",
    "\n",
    "\n",
    "# è®¾ç½®è®°å¿†\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "agent = create_agent(\n",
    "    model= llm,\n",
    "    system_prompt= SYSTEM_PROMPT,\n",
    "    tools=[get_user_location, get_weather_for_location],\n",
    "    context_schema=Context,\n",
    "    response_format=ResponseFormat,\n",
    "    checkpointer=checkpointer\n",
    ")\n",
    "\n",
    "#è¿è¡Œä»£ç†\n",
    "# thread_id æ˜¯ç»™å®šå¯¹è¯çš„å”¯ä¸€æ ‡è¯†ç¬¦\n",
    "config = {\"configurable\":{\"thread_id\":\"1\"}}\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\":\"user\",\"content\": \"å¤–é¢çš„å¤©æ°”æ€ä¹ˆæ ·\"}]},\n",
    "    config=config,\n",
    "    context=Context(user_id=\"1\")\n",
    ")\n",
    "print(response['structured_response'])\n",
    "# ResponseFormat(\n",
    "#     punny_response=\"ä½›ç½—é‡Œè¾¾ä»Šå¤©ä¾ç„¶æ˜¯'é˜³å…‰ç¿çƒ‚'çš„ä¸€å¤©ï¼é˜³å…‰æ­£åœ¨æ’­æ”¾'rey-dio'çƒ­é—¨æ­Œæ›²ï¼æˆ‘å¾—è¯´ï¼Œè¿™æ˜¯è¿›è¡Œ'solar-bration'çš„å®Œç¾å¤©æ°”ï¼å¦‚æœä½ å¸Œæœ›ä¸‹é›¨ï¼Œææ€•è¿™ä¸ªæƒ³æ³•å·²ç»'è¢«å†²èµ°'äº†â€”â€”é¢„æŠ¥ä»ç„¶'æ¸…æ™°åœ°'ç¿çƒ‚ï¼\",\n",
    "#     weather_conditions=\"ä½›ç½—é‡Œè¾¾æ€»æ˜¯é˜³å…‰æ˜åªšï¼\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f11b9cd-fde3-4500-8f5e-e377cd4054d2",
   "metadata": {},
   "source": [
    "### ä½¿ç”¨wrap_model_callå®ç°åŠ¨æ€æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe008e6f-d524-42bd-be52-0ccdfc304238",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "\n",
    "advanced_model = llm\n",
    "\n",
    "basic_model = ChatOpenAI(\n",
    "    openai_api_base=\"https://ark.cn-beijing.volces.com/api/v3\",\n",
    "    openai_api_key=api_key,\t# app_key\n",
    "    model_name=\"doubao-seed-1-6-flash-250828\",\t# æ¨ç†æ¥å…¥ç‚¹\n",
    ")\n",
    "\n",
    "@wrap_model_call\n",
    "def dynamic_model_selection(request: ModelRequest, handler) -> ModelResponse:\n",
    "    \"\"\"æ ¹æ®å¯¹äºå¤æ‚æ€§é€‰æ‹©æ¨¡å‹\"\"\"\n",
    "    message_count = len(request.state[\"messages\"])\n",
    "    print(message_count)\n",
    "\n",
    "    if message_count>4:\n",
    "        model = advanced_model\n",
    "    else:\n",
    "        model = basic_model\n",
    "\n",
    "    request.model = model\n",
    "    return handler(request)\n",
    "\n",
    "agent = create_agent(\n",
    "    model = basic_model,\n",
    "    #tools=tools,\n",
    "    middleware=[dynamic_model_selection]\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc56977-7914-4cb8-9386-275663312f79",
   "metadata": {},
   "source": [
    "## å®šä¹‰å·¥å…·ï¼Œä¼ é€’ç»™æ™ºèƒ½ä½“, å·¥å…·å¤„ç†é”™è¯¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e1dce4d-231a-44e4-843f-d294f786c441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='è§£é‡Šæœºå™¨å­¦ä¹ ', additional_kwargs={}, response_metadata={}, id='a5b20061-2af2-4caf-a6bd-a31b9fc8fe21'),\n",
       "  AIMessage(content='æœºå™¨å­¦ä¹ æ˜¯è®©è®¡ç®—æœºé€šè¿‡æ•°æ®è‡ªå·±â€œå­¦ä¹ â€å¹¶å˜å¾—æ›´èªæ˜çš„æŠ€æœ¯ã€‚ç®€å•è¯´ï¼Œå°±åƒæ•™å°å­©è®¤æ°´æœï¼šä½ ç»™è®¡ç®—æœºçœ‹å¾ˆå¤šè‹¹æœã€é¦™è•‰çš„å›¾ç‰‡ï¼ˆæ•°æ®ï¼‰ï¼Œå®ƒä¼šæ‰¾å‡ºè§„å¾‹ï¼ˆæ¯”å¦‚è‹¹æœæ˜¯åœ†çš„ã€çº¢è‰²çš„ï¼‰ï¼Œä¹‹åå†çœ‹åˆ°æ–°å›¾ç‰‡æ—¶ï¼Œå°±èƒ½è‡ªå·±åˆ¤æ–­æ˜¯ä¸æ˜¯è‹¹æœã€‚  \\n\\nå®ƒä¸ç”¨äººæ‰‹åŠ¨å†™æ­»è§„åˆ™ï¼Œè€Œæ˜¯é€šè¿‡å¤§é‡æ•°æ®è®­ç»ƒï¼Œè‡ªå·±æ€»ç»“æ¨¡å¼ï¼Œæ¯”å¦‚é¢„æµ‹å¤©æ°”ã€æ¨èç”µå½±ã€è¯†åˆ«åƒåœ¾é‚®ä»¶éƒ½é å®ƒã€‚æ ¸å¿ƒå°±æ˜¯â€œä»ç»éªŒï¼ˆæ•°æ®ï¼‰ä¸­æ”¹è¿›â€ã€‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 471, 'prompt_tokens': 499, 'total_tokens': 970, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 357, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'doubao-seed-1-6-250615', 'system_fingerprint': None, 'id': '021768916329614d6b0e46812eb6ca5f421e6552139c58c2ea65d', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019bdba1-2379-7163-80bf-efec3134135d-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 499, 'output_tokens': 471, 'total_tokens': 970, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 357}})]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain.agents.middleware import wrap_tool_call\n",
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "from typing import TypedDict\n",
    "\n",
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"æœç´¢ä¿¡æ¯\"\"\"\n",
    "    return f\"ç»“æœï¼š{query}\"\n",
    "\n",
    "@tool\n",
    "def get_weather(location: str)  -> str:\n",
    "    \"\"\"è·å–ä½ç½®çš„å¤©æ°”ä¿¡æ¯\"\"\"\n",
    "    return f\"{location}çš„å¤©æ°”ï¼šæ™´æœ—ï¼Œ32åº¦ï¼\"\n",
    "\n",
    "@wrap_tool_call\n",
    "def handle_tool_errors(request, handler):\n",
    "    \"\"\"ä½¿ç”¨è‡ªå®šä¹‰æ¶ˆæ¯å¤„ç†å·¥å…·æ‰§è¡Œé”™è¯¯\"\"\"\n",
    "    try:\n",
    "        return handler(request)\n",
    "    except Exception as e:\n",
    "        #å‘æ¨¡å‹è¿”å›è‡ªå®šä¹‰éŒ¯èª¤ä¿¡æ¯\n",
    "        return ToolMessage(\n",
    "            content=f\"å·¥å…·é”™è¯¯ï¼Œè¯·æ£€æŸ¥å¹¶é‡è¯•ã€‚({str(e)})\",\n",
    "            tool_call_id = request.tool_call[\"id\"]\n",
    "        )\n",
    "\n",
    "class Context(TypedDict):\n",
    "    user_role: str\n",
    "\n",
    "@dynamic_prompt\n",
    "def user_role_prompt(request: ModelRequest) -> str:\n",
    "    \"\"\"æ ¹æ®ç”¨æˆ·è§’è‰²ç”Ÿäº§ç³»ç»Ÿæç¤º\"\"\"\n",
    "    user_role = request.runtime.context.get(\"user_role\",\"user\")\n",
    "    base_promt = \"ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹ã€‚\"\n",
    "\n",
    "    if user_role == \"expert\":\n",
    "        return f\"{base_promt}æä¾›è¯¦ç»†çš„æŠ€æœ¯å“åº”\"\n",
    "    elif user_role == \"beginner\":\n",
    "        return f\"{base_promt}ç®€å•è§£é‡Šæ¦‚å¿µï¼Œé¿å…ä½¿ç”¨è¡Œè¯\"\n",
    "\n",
    "    return base_promt\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model = llm,\n",
    "    tools=[search, get_weather],\n",
    "    middleware=[handle_tool_errors, user_role_prompt],\n",
    "    context_schema=Context\n",
    ")\n",
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"è§£é‡Šæœºå™¨å­¦ä¹ \"}]},\n",
    "    context={\"user_role\": \"beginner\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f9edc2-5bad-47cb-a909-fac8a2f875d7",
   "metadata": {},
   "source": [
    "## ç»“æ„åŒ–è¾“å‡º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e4e39a2-6e6e-4843-bce5-3a9f930d99dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ContractInfo(name='John Doe', email='john@example.com', phone='(555) 123-4567')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.structured_output import ToolStrategy\n",
    "from langchain.agents.structured_output import ProviderStrategy\n",
    "\n",
    "class ContractInfo(BaseModel):\n",
    "    name: str\n",
    "    email:str\n",
    "    phone:str\n",
    "\n",
    "agent = create_agent(\n",
    "    model = llm,\n",
    "    tools=[search],\n",
    "    #response_format=ToolStrategy(ContractInfo)\n",
    "    response_format = ProviderStrategy(ContractInfo)\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"ä»ä»¥ä¸‹å†…å®¹æå–è”ç³»ä¿¡æ¯ï¼šJohn Doe, john@example.com, (555) 123-4567\"}]\n",
    "})\n",
    "result[\"structured_response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cf3c0f-326d-4572-a902-957941e0eee5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
